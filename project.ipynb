{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.Data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Loaders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.1 MNIST Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,),(0.5,)),\n",
    "    ])\n",
    "batch_size = 64\n",
    "\n",
    "datasets_save_dir = 'Data/'\n",
    "\n",
    "train_data = datasets.MNIST(root=datasets_save_dir,download=True,train=True, \n",
    "    transform=transform)\n",
    "test_data = datasets.MNIST(root=datasets_save_dir,download=True,train=False, \n",
    "    transform=transform)\n",
    "\n",
    "train_dataloader = DataLoader(train_data,batch_size=batch_size,\n",
    "    shuffle=True)\n",
    "test_dataloader = DataLoader(test_data,batch_size=batch_size,shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.2 Subsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "subset_sizes = [1000*i for i in range(1,6)] \n",
    "\n",
    "subset_loaders = []\n",
    "for subset_size in subset_sizes:\n",
    "    subset, _ = random_split(train_data, [subset_size, len(train_data) - subset_size])\n",
    "    subset_loader = DataLoader(subset, batch_size=batch_size, shuffle=True)\n",
    "    subset_loaders.append(subset_loader)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Data shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "for images,labels in train_dataloader:\n",
    "    print(images.shape)\n",
    "    print(labels.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Fcnn(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.block_1 = nn.Sequential(\n",
    "            nn.Linear(28*28,256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256,64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64,10),\n",
    "            nn.Softmax()\n",
    "        )\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = self.block_1(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epochs:int,model,optimizer,criterion,data):\n",
    "    model.train()\n",
    "    loss_history = []\n",
    "    for epoch in range(epochs):\n",
    "        for batch, (images,labels) in enumerate(data):\n",
    "            images = images.view(images.shape[0],-1)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            output = model(images)\n",
    "\n",
    "            loss = criterion(output,labels) \n",
    "            loss.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "\n",
    "            if (batch+1) % 100 == 0:\n",
    "                print(f'epoch: {epoch+1}, step: {batch+1}/{len(data)} , loss: {loss.item():.4f}')\n",
    "        loss_history.append(loss.item())\n",
    "            \n",
    "    print('Finished training!')\n",
    "    return loss_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1, step: 100/3750 , loss: 1.8908\n",
      "epoch: 1, step: 200/3750 , loss: 1.7894\n",
      "epoch: 1, step: 300/3750 , loss: 1.5904\n",
      "epoch: 1, step: 400/3750 , loss: 1.7767\n",
      "epoch: 1, step: 500/3750 , loss: 1.6523\n",
      "epoch: 1, step: 600/3750 , loss: 1.6694\n",
      "epoch: 1, step: 700/3750 , loss: 1.6568\n",
      "epoch: 1, step: 800/3750 , loss: 1.7092\n",
      "epoch: 1, step: 900/3750 , loss: 1.5276\n",
      "epoch: 1, step: 1000/3750 , loss: 1.6782\n",
      "epoch: 1, step: 1100/3750 , loss: 1.5820\n",
      "epoch: 1, step: 1200/3750 , loss: 1.5494\n",
      "epoch: 1, step: 1300/3750 , loss: 1.4786\n",
      "epoch: 1, step: 1400/3750 , loss: 1.5354\n",
      "epoch: 1, step: 1500/3750 , loss: 1.5785\n",
      "epoch: 1, step: 1600/3750 , loss: 1.5732\n",
      "epoch: 1, step: 1700/3750 , loss: 1.6300\n",
      "epoch: 1, step: 1800/3750 , loss: 1.5348\n",
      "epoch: 1, step: 1900/3750 , loss: 1.6057\n",
      "epoch: 1, step: 2000/3750 , loss: 1.5254\n",
      "epoch: 1, step: 2100/3750 , loss: 1.5164\n",
      "epoch: 1, step: 2200/3750 , loss: 1.5454\n",
      "epoch: 1, step: 2300/3750 , loss: 1.5258\n",
      "epoch: 1, step: 2400/3750 , loss: 1.5317\n",
      "epoch: 1, step: 2500/3750 , loss: 1.6042\n",
      "epoch: 1, step: 2600/3750 , loss: 1.4619\n",
      "epoch: 1, step: 2700/3750 , loss: 1.6787\n",
      "epoch: 1, step: 2800/3750 , loss: 1.7137\n",
      "epoch: 1, step: 2900/3750 , loss: 1.5952\n",
      "epoch: 1, step: 3000/3750 , loss: 1.6480\n",
      "epoch: 1, step: 3100/3750 , loss: 1.5728\n",
      "epoch: 1, step: 3200/3750 , loss: 1.5646\n",
      "epoch: 1, step: 3300/3750 , loss: 1.5071\n",
      "epoch: 1, step: 3400/3750 , loss: 1.6956\n",
      "epoch: 1, step: 3500/3750 , loss: 1.6915\n",
      "epoch: 1, step: 3600/3750 , loss: 1.5802\n",
      "epoch: 1, step: 3700/3750 , loss: 1.4685\n",
      "epoch: 2, step: 100/3750 , loss: 1.4620\n",
      "epoch: 2, step: 200/3750 , loss: 1.8109\n",
      "epoch: 2, step: 300/3750 , loss: 1.5910\n",
      "epoch: 2, step: 400/3750 , loss: 1.5161\n",
      "epoch: 2, step: 500/3750 , loss: 1.5892\n",
      "epoch: 2, step: 600/3750 , loss: 1.5783\n",
      "epoch: 2, step: 700/3750 , loss: 1.5420\n",
      "epoch: 2, step: 800/3750 , loss: 1.6932\n",
      "epoch: 2, step: 900/3750 , loss: 1.5272\n",
      "epoch: 2, step: 1000/3750 , loss: 1.5145\n",
      "epoch: 2, step: 1100/3750 , loss: 1.5885\n",
      "epoch: 2, step: 1200/3750 , loss: 1.4648\n",
      "epoch: 2, step: 1300/3750 , loss: 1.6067\n",
      "epoch: 2, step: 1400/3750 , loss: 1.5237\n",
      "epoch: 2, step: 1500/3750 , loss: 1.4678\n",
      "epoch: 2, step: 1600/3750 , loss: 1.4612\n",
      "epoch: 2, step: 1700/3750 , loss: 1.4682\n",
      "epoch: 2, step: 1800/3750 , loss: 1.4612\n",
      "epoch: 2, step: 1900/3750 , loss: 1.4808\n",
      "epoch: 2, step: 2000/3750 , loss: 1.5709\n",
      "epoch: 2, step: 2100/3750 , loss: 1.7701\n",
      "epoch: 2, step: 2200/3750 , loss: 1.5882\n",
      "epoch: 2, step: 2300/3750 , loss: 1.5742\n",
      "epoch: 2, step: 2400/3750 , loss: 1.4613\n",
      "epoch: 2, step: 2500/3750 , loss: 1.4663\n",
      "epoch: 2, step: 2600/3750 , loss: 1.6143\n",
      "epoch: 2, step: 2700/3750 , loss: 1.5698\n",
      "epoch: 2, step: 2800/3750 , loss: 1.4848\n",
      "epoch: 2, step: 2900/3750 , loss: 1.5236\n",
      "epoch: 2, step: 3000/3750 , loss: 1.5240\n",
      "epoch: 2, step: 3100/3750 , loss: 1.5245\n",
      "epoch: 2, step: 3200/3750 , loss: 1.5718\n",
      "epoch: 2, step: 3300/3750 , loss: 1.4618\n",
      "epoch: 2, step: 3400/3750 , loss: 1.4615\n",
      "epoch: 2, step: 3500/3750 , loss: 1.5862\n",
      "epoch: 2, step: 3600/3750 , loss: 1.5253\n",
      "epoch: 2, step: 3700/3750 , loss: 1.4612\n",
      "epoch: 3, step: 100/3750 , loss: 1.5029\n",
      "epoch: 3, step: 200/3750 , loss: 1.4615\n",
      "epoch: 3, step: 300/3750 , loss: 1.5742\n",
      "epoch: 3, step: 400/3750 , loss: 1.4613\n",
      "epoch: 3, step: 500/3750 , loss: 1.4998\n",
      "epoch: 3, step: 600/3750 , loss: 1.5232\n",
      "epoch: 3, step: 700/3750 , loss: 1.5886\n",
      "epoch: 3, step: 800/3750 , loss: 1.5106\n",
      "epoch: 3, step: 900/3750 , loss: 1.4614\n",
      "epoch: 3, step: 1000/3750 , loss: 1.4881\n",
      "epoch: 3, step: 1100/3750 , loss: 1.5211\n",
      "epoch: 3, step: 1200/3750 , loss: 1.6507\n",
      "epoch: 3, step: 1300/3750 , loss: 1.4614\n",
      "epoch: 3, step: 1400/3750 , loss: 1.5640\n",
      "epoch: 3, step: 1500/3750 , loss: 1.5272\n",
      "epoch: 3, step: 1600/3750 , loss: 1.5254\n",
      "epoch: 3, step: 1700/3750 , loss: 1.7044\n",
      "epoch: 3, step: 1800/3750 , loss: 1.4619\n",
      "epoch: 3, step: 1900/3750 , loss: 1.5000\n",
      "epoch: 3, step: 2000/3750 , loss: 1.5238\n",
      "epoch: 3, step: 2100/3750 , loss: 1.6473\n",
      "epoch: 3, step: 2200/3750 , loss: 1.5249\n",
      "epoch: 3, step: 2300/3750 , loss: 1.4612\n",
      "epoch: 3, step: 2400/3750 , loss: 1.5237\n",
      "epoch: 3, step: 2500/3750 , loss: 1.5511\n",
      "epoch: 3, step: 2600/3750 , loss: 1.5721\n",
      "epoch: 3, step: 2700/3750 , loss: 1.5794\n",
      "epoch: 3, step: 2800/3750 , loss: 1.5237\n",
      "epoch: 3, step: 2900/3750 , loss: 1.4612\n",
      "epoch: 3, step: 3000/3750 , loss: 1.4612\n",
      "epoch: 3, step: 3100/3750 , loss: 1.5861\n",
      "epoch: 3, step: 3200/3750 , loss: 1.4612\n",
      "epoch: 3, step: 3300/3750 , loss: 1.6487\n",
      "epoch: 3, step: 3400/3750 , loss: 1.4869\n",
      "epoch: 3, step: 3500/3750 , loss: 1.5806\n",
      "epoch: 3, step: 3600/3750 , loss: 1.6429\n",
      "epoch: 3, step: 3700/3750 , loss: 1.5246\n",
      "Finished training!\n"
     ]
    }
   ],
   "source": [
    "model = Fcnn()\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "train(3,model,optimizer,criterion,train_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, data):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for batch, (images,labels) in enumerate(data):\n",
    "            images = images.view(images.shape[0],-1)\n",
    "\n",
    "            output = model(images)\n",
    "\n",
    "            pred = output.data.max(1,keepdim=True)[1]\n",
    "            \n",
    "            labels = labels.data.view_as(pred)\n",
    "            correct += pred.eq(labels).sum()\n",
    "    accuracy = correct/len(data.dataset)\n",
    "    print(f'Accuracy: {accuracy:.3f}')\n",
    "    return accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.970\n"
     ]
    }
   ],
   "source": [
    "\n",
    "test(model)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Early stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopper:\n",
    "    def __init__(self, patience=1, min_delta=0):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.counter = 0\n",
    "        self.min_validation_loss = float('inf')\n",
    "\n",
    "    def early_stop(self, validation_loss):\n",
    "        if validation_loss < self.min_validation_loss:\n",
    "            self.min_validation_loss = validation_loss\n",
    "            self.counter = 0\n",
    "        elif validation_loss > (self.min_validation_loss + self.min_delta):\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                return True\n",
    "        return False\n",
    "    \n",
    "def train_es(epochs:int,model,optimizer,criterion,dataloader):\n",
    "    early_stopper = EarlyStopper(patience=2, min_delta=10)\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        batch_loss_history = []\n",
    "        for batch, (images,labels) in enumerate(dataloader):\n",
    "            images = images.view(images.shape[0],-1)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            output = model(images)\n",
    "\n",
    "            loss = criterion(output,labels)\n",
    "            loss.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "            if (batch+1) % 100 == 0:\n",
    "                print(f'epoch: {epoch+1}, step: {batch+1}/{len(dataloader)} , loss: {loss.item():.4f}')\n",
    "            batch_loss_history.append(loss.item().numpy())\n",
    "        \n",
    "        print(torch.float)\n",
    "        epoch_avg_loss = np.average(batch_loss_history)\n",
    "        if early_stopper.early_stop(epoch_avg_loss):\n",
    "            print('Early stopping!')\n",
    "            break\n",
    "        \n",
    "        print(f'Epoch: {epoch+1}, avg_loss = {epoch_avg_loss}')\n",
    "    print('Finished training!')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/luki/Dokumenty/Projekty/sieci_projekt2/venv/lib64/python3.11/site-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return self._call_impl(*args, **kwargs)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'float' object has no attribute 'numpy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdam(model\u001b[38;5;241m.\u001b[39mparameters())\n\u001b[1;32m      3\u001b[0m criterion \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mCrossEntropyLoss()\n\u001b[0;32m----> 5\u001b[0m \u001b[43mtrain_es\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdataloader\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43msubset_loaders\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[24], line 36\u001b[0m, in \u001b[0;36mtrain_es\u001b[0;34m(epochs, model, optimizer, criterion, dataloader)\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (batch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m100\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     35\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mepoch: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, step: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbatch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(dataloader)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m , loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss\u001b[38;5;241m.\u001b[39mitem()\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 36\u001b[0m     batch_loss_history\u001b[38;5;241m.\u001b[39mappend(\u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m())\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28mprint\u001b[39m(torch\u001b[38;5;241m.\u001b[39mfloat)\n\u001b[1;32m     39\u001b[0m epoch_avg_loss \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39maverage(batch_loss_history)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'float' object has no attribute 'numpy'"
     ]
    }
   ],
   "source": [
    "model = Fcnn()\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "train_es(20,model,optimizer,criterion,dataloader = subset_loaders[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Training on different subsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/luki/Dokumenty/Projekty/sieci_projekt2/venv/lib64/python3.11/site-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return self._call_impl(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished training!\n",
      "Accuracy: 0.685\n",
      "Accuracy: 0.683\n",
      "Finished training!\n",
      "Accuracy: 0.791\n",
      "Accuracy: 0.780\n",
      "Finished training!\n",
      "Accuracy: 0.719\n",
      "Accuracy: 0.710\n",
      "epoch: 1, step: 100/125 , loss: 1.8584\n",
      "epoch: 2, step: 100/125 , loss: 1.6340\n",
      "epoch: 3, step: 100/125 , loss: 1.6458\n",
      "Finished training!\n",
      "Accuracy: 0.818\n",
      "Accuracy: 0.812\n",
      "epoch: 1, step: 100/157 , loss: 1.7036\n",
      "epoch: 2, step: 100/157 , loss: 1.7441\n",
      "epoch: 3, step: 100/157 , loss: 1.5964\n",
      "Finished training!\n",
      "Accuracy: 0.840\n",
      "Accuracy: 0.843\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "subset_loss_history = []\n",
    "subset_accuracy_train = []\n",
    "subset_accuracy_test = []\n",
    "for subset in subset_loaders:\n",
    "    model = Fcnn()\n",
    "    optimizer = torch.optim.Adam(model.parameters())\n",
    "    loss_history = train(3,model,optimizer,criterion,subset)\n",
    "    subset_loss_history.append(loss_history)\n",
    "\n",
    "    accuracy_test = test(model,test_dataloader)\n",
    "    accuracy_train = test(model,train_dataloader)\n",
    "    \n",
    "    subset_accuracy_train.append(accuracy_train)\n",
    "    subset_accuracy_test.append(accuracy_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mplt\u001b[49m\u001b[38;5;241m.\u001b[39mplot(subset_sizes,subset_accuracy_train, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTrain accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      2\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(subset_sizes,subset_accuracy_test ,label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTest accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "plt.plot(subset_sizes,subset_accuracy_train, label='Train accuracy')\n",
    "plt.plot(subset_sizes,subset_accuracy_test ,label='Test accuracy')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
